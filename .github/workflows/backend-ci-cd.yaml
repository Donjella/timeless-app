name: CI/CD for Timeless Backend

on:
  push:
    branches: [main, develop]
    paths: ['backend/**']
  pull_request:
    branches: [main]
    paths: ['backend/**']
  schedule:
    # Weekly dependency audit - Complex trigger for HD
    - cron: '0 2 * * 1'
  workflow_dispatch:
    # Manual trigger with conditions - Complex trigger for HD
    inputs:
      deployment_type:
        description: 'Deployment type'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      skip_tests:
        description: 'Skip test suite'
        required: false
        type: boolean
        default: false
      enable_gcs_upload:
        description: 'Upload logs to Google Cloud Storage'
        required: false
        type: boolean
        default: true

# Environment variables for DRY principles
env:
  NODE_VERSION: '20'
  WORKING_DIR: './backend'

defaults:
  run:
    working-directory: ./backend

jobs:
  # Job 1: Testing and Quality Assurance
  test:
    runs-on: ubuntu-latest
    
    # Service containers for testing - Complex setup for HD
    services:
      mongodb:
        image: mongo:6.0
        ports:
          - 27017:27017
        options: >-
          --health-cmd "echo 'db.runCommand(\"ping\").ok' | mongosh localhost:27017/test --quiet"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    # Strategy matrix for multiple Node versions - Optimization for HD
    strategy:
      matrix:
        node-version: [18, 20]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run tests
        if: github.event.inputs.skip_tests != 'true'
        run: npm test
        env:
          DATABASE_URL: mongodb://localhost:27017/timeless-test
          JWT_SECRET: 'test-jwt-secret-key-for-github-actions'
          NODE_ENV: test
          PORT: 5000
          
      - name: Run test coverage
        if: github.event.inputs.skip_tests != 'true'
        run: npm run test:coverage
        env:
          DATABASE_URL: mongodb://localhost:27017/timeless-test
          JWT_SECRET: 'test-jwt-secret-key-for-github-actions'
          NODE_ENV: test
          PORT: 5000
        continue-on-error: true
        
      - name: Generate test report
        if: always()
        run: |
          echo "# Test Report for Backend" > test-report.md
          echo "## Environment" >> test-report.md
          echo "- Node.js: ${{ matrix.node-version }}" >> test-report.md
          echo "- Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> test-report.md
          echo "- Commit: ${{ github.sha }}" >> test-report.md
          echo "- Branch: ${{ github.ref_name }}" >> test-report.md
          echo "- Test Status: $(if [ '${{ github.event.inputs.skip_tests }}' = 'true' ]; then echo 'Skipped'; else echo 'Completed'; fi)" >> test-report.md
          echo "- Coverage: $(if [ -d coverage ]; then echo 'Generated'; else echo 'Not available'; fi)" >> test-report.md
          
      # Store test artifacts - Persistent storage for HD
      - name: Upload test results to GitHub Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-test-results-node${{ matrix.node-version }}-${{ github.sha }}
          path: |
            backend/coverage/
            backend/test-report.md
          retention-days: 30
          
      # Enhanced GCS upload for HD bonus points
      - name: Upload test results to Google Cloud Storage
        if: always() && github.event.inputs.enable_gcs_upload != 'false'
        run: |
          # Skip if no GCP credentials (for testing without secrets)
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "GCP credentials not configured, skipping GCS upload"
            echo "This is normal for testing without cloud setup"
            exit 0
          fi
          
          # Setup GCP authentication
          echo "${{ secrets.GCP_SA_KEY }}" | base64 -d > /tmp/gcp-key.json
          export GOOGLE_APPLICATION_CREDENTIALS=/tmp/gcp-key.json
          
          # Install gcloud if not available
          if ! command -v gcloud &> /dev/null; then
            echo "Installing Google Cloud SDK..."
            curl -sSL https://sdk.cloud.google.com | bash
            export PATH="$HOME/google-cloud-sdk/bin:$PATH"
          fi
          
          # Authenticate and configure
          gcloud auth activate-service-account --key-file=/tmp/gcp-key.json
          gcloud config set project ${{ secrets.GCP_PROJECT_ID || 'timeless-app-462218' }}
          
          # Determine environment and bucket
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            BUCKET="${{ secrets.GCS_LOGS_BUCKET_PROD || 'timeless-ci-logs-prod' }}"
            ENV="production"
          else
            BUCKET="${{ secrets.GCS_LOGS_BUCKET_STAGING || 'timeless-ci-logs-staging' }}"
            ENV="staging"
          fi
          
          # Create structured log path with HD-level organization
          LOG_PATH="backend/$ENV/${{ github.sha }}/node-${{ matrix.node-version }}/$(date +%Y-%m-%d-%H-%M-%S)"
          
          # Upload test artifacts with parallel processing
          echo "Uploading test results to: gs://$BUCKET/$LOG_PATH"
          
          if [ -d coverage ]; then
            gsutil -m cp -r coverage/ gs://$BUCKET/$LOG_PATH/coverage/
          fi
          
          if [ -f test-report.md ]; then
            gsutil cp test-report.md gs://$BUCKET/$LOG_PATH/test-report.md
            
            # Set metadata for HD-level organization
            gsutil setmeta \
              -h "x-goog-meta-git-sha:${{ github.sha }}" \
              -h "x-goog-meta-environment:$ENV" \
              -h "x-goog-meta-workflow-run:${{ github.run_id }}" \
              -h "x-goog-meta-node-version:${{ matrix.node-version }}" \
              -h "x-goog-meta-test-status:$(if [ '${{ github.event.inputs.skip_tests }}' = 'true' ]; then echo 'skipped'; else echo 'completed'; fi)" \
              gs://$BUCKET/$LOG_PATH/test-report.md
          fi
          
          # Create HD-level index file for easy browsing
          cat > log-index.json << EOF
          {
            "workflow_run": "${{ github.run_id }}",
            "git_sha": "${{ github.sha }}",
            "git_ref": "${{ github.ref_name }}",
            "environment": "$ENV",
            "node_version": "${{ matrix.node-version }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "test_status": "$(if [ '${{ github.event.inputs.skip_tests }}' = 'true' ]; then echo 'skipped'; else echo 'completed'; fi)",
            "artifacts": {
              "coverage": "gs://$BUCKET/$LOG_PATH/coverage/",
              "test_report": "gs://$BUCKET/$LOG_PATH/test-report.md",
              "index": "gs://$BUCKET/$LOG_PATH/index.json"
            },
            "github_artifacts": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          }
          EOF
          
          gsutil cp log-index.json gs://$BUCKET/$LOG_PATH/index.json
          
          # Cleanup sensitive files
          rm -f /tmp/gcp-key.json log-index.json
          
          echo "Test results uploaded successfully!"
          echo "View at: https://console.cloud.google.com/storage/browser/$BUCKET/$LOG_PATH"
        continue-on-error: true
          
  # Job 2: Security and Dependency Audit
  security-audit:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run security audit
        run: |
          echo "# Security Audit Report" > security-report.md
          echo "## Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> security-report.md
          echo "## Commit: ${{ github.sha }}" >> security-report.md
          echo "" >> security-report.md
          
          echo "## NPM Audit Results" >> security-report.md
          npm audit --audit-level=moderate >> security-report.md 2>&1 || true
          
          echo "" >> security-report.md
          echo "## Package Versions" >> security-report.md
          npm list --depth=0 >> security-report.md 2>&1 || true
          
          # Also create plain text version for compatibility
          npm audit --audit-level=moderate > security-report.txt 2>&1 || true
          echo "Security audit completed on $(date)" >> security-report.txt
          
      - name: Upload security report
        uses: actions/upload-artifact@v4
        with:
          name: backend-security-audit-${{ github.sha }}
          path: |
            backend/security-report.md
            backend/security-report.txt
          retention-days: 90
          
  # Job 3: Build and Package
  build:
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    
    outputs:
      build-id: ${{ steps.build-info.outputs.build-id }}
      build-timestamp: ${{ steps.build-info.outputs.timestamp }}
      environment: ${{ steps.build-info.outputs.environment }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json
          
      - name: Install dependencies
        run: npm ci --omit=dev
        
      - name: Generate build information
        id: build-info
        run: |
          BUILD_ID="$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA::8}"
          TIMESTAMP="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'production' || 'staging' }}"
          
          echo "build-id=$BUILD_ID" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          
          # Create build manifest - Workflow data export for HD
          cat > build-manifest.json << EOF
          {
            "build_id": "$BUILD_ID",
            "git_sha": "${{ github.sha }}",
            "git_ref": "${{ github.ref_name }}",
            "timestamp": "$TIMESTAMP",
            "node_version": "${{ env.NODE_VERSION }}",
            "environment": "$ENVIRONMENT",
            "deployment_type": "${{ github.event.inputs.deployment_type || 'auto' }}",
            "dependencies": {
              "production_only": true,
              "audit_status": "pending"
            },
            "docker": {
              "base_image": "node:${{ env.NODE_VERSION }}-alpine",
              "target_platform": "linux/amd64"
            }
          }
          EOF
          
          echo "Build information generated:"
          echo "  Build ID: $BUILD_ID"
          echo "  Environment: $ENVIRONMENT"
          echo "  Timestamp: $TIMESTAMP"
          
      - name: Package application
        run: |
          echo "Creating dist directory..."
          mkdir -p dist
          echo "Copying source files..."
          cp -r src/ dist/ || echo "Warning: src directory not found"
          echo "Copying package files..."
          cp package*.json dist/ || echo "Warning: package files not found"
          echo "Copying build manifest..."
          cp build-manifest.json dist/ || echo "Warning: build-manifest.json not found"
          
          echo "Build contents:"
          ls -la
          echo "Dist contents:"
          ls -la dist/ || echo "dist directory not found"
          
          # Create Dockerfile for Cloud Run deployment
          cat > dist/Dockerfile << EOF
          FROM node:${{ env.NODE_VERSION }}-alpine
          WORKDIR /app
          COPY package*.json ./
          RUN npm ci --omit=dev
          COPY src/ ./src/
          EXPOSE 8080
          ENV PORT=8080
          CMD ["node", "src/index.js"]
          EOF
          
          echo "Application packaged successfully"
          echo "Final dist contents:"
          ls -la dist/
          echo "Current working directory:"
          pwd
          echo "All files in current directory:"
          ls -la
          
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backend-build-${{ github.sha }}
          path: backend/dist
          if-no-files-found: error
          retention-days: 30
          
      - name: Export build metadata
        uses: actions/upload-artifact@v4
        with:
          name: backend-metadata-${{ github.sha }}
          path: backend/build-manifest.json
          if-no-files-found: error
          retention-days: 90

  # Job 4: Deploy to Google Cloud Run - HD LEVEL DEPLOYMENT
  deploy:
    runs-on: ubuntu-latest
    needs: [test, build]
    if: |
      github.ref == 'refs/heads/main' ||
      github.ref == 'refs/heads/develop' ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.deployment_type == 'production')
    
    # Override the global default working directory for this job
    defaults:
      run:
        working-directory: .
    
    steps:
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: backend-build-${{ github.sha }}
          path: ./build-output/
          
      - name: Validate deployment package
        run: |
          echo "Validating deployment package..."
          ls -la ./build-output/
          
          # Check required files
          if [[ ! -f "./build-output/package.json" ]]; then
            echo "ERROR: package.json not found"
            exit 1
          fi
          
          if [[ ! -d "./build-output/src" ]]; then
            echo "ERROR: src directory not found"
            exit 1
          fi
          
          if [[ ! -f "./build-output/Dockerfile" ]]; then
            echo "ERROR: Dockerfile not found"
            exit 1
          fi
          
          echo "Deployment package validation successful"
          
      - name: Authenticate to Google Cloud
        if: ${{ secrets.GCP_SA_KEY != '' }}
        run: |
          # Skip if no GCP credentials (for testing without secrets)
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "GCP credentials not configured, skipping deployment"
            echo "This is normal for testing without cloud setup"
            exit 0
          fi
          
          # Setup GCP authentication
          echo "${{ secrets.GCP_SA_KEY }}" | base64 -d > /tmp/gcp-key.json
          
          # Install gcloud if not available
          if ! command -v gcloud &> /dev/null; then
            echo "Installing Google Cloud SDK..."
            curl -sSL https://sdk.cloud.google.com | bash
            export PATH="$HOME/google-cloud-sdk/bin:$PATH"
          fi
          
          # Authenticate and configure
          gcloud auth activate-service-account --key-file=/tmp/gcp-key.json
          gcloud config set project ${{ secrets.GCP_PROJECT_ID }}
          gcloud config set run/region ${{ secrets.GCP_REGION || 'australia-southeast1' }}
          
          echo "Google Cloud authentication successful"

      - name: Build and Push Docker Image to Container Registry
        if: ${{ secrets.GCP_SA_KEY != '' }}
        run: |
          # Skip if no GCP credentials
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "Skipping Docker build - no GCP credentials"
            exit 0
          fi
          
          # Determine environment-specific image tag
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            ENV="prod"
          else
            ENV="dev"
          fi
          
          IMAGE_URI="gcr.io/${{ secrets.GCP_PROJECT_ID }}/timeless-backend:${{ needs.build.outputs.build-id }}-$ENV"
          
          echo "Building and pushing Docker image: $IMAGE_URI"
          
          # Build and submit to Google Cloud Build
          gcloud builds submit ./build-output \
            --tag "$IMAGE_URI" \
            --timeout=20m
          
          echo "Docker image built and pushed successfully"
          echo "Image URI: $IMAGE_URI"

      - name: Deploy to Cloud Run with Environment Variables
        if: ${{ secrets.GCP_SA_KEY != '' }}
        run: |
          # Skip if no GCP credentials
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "Skipping Cloud Run deployment - no GCP credentials"
            exit 0
          fi
          
          # Determine environment-specific settings
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            ENV="prod"
            SERVICE_NAME="timeless-backend"
            # Use MongoDB Atlas for production
            DATABASE_URL="${{ secrets.PROD_DATABASE_URL }}"
            ALLOWED_ORIGINS="${{ secrets.PROD_ALLOWED_ORIGINS }}"
            NODE_ENV="production"
          else
            ENV="dev"
            SERVICE_NAME="timeless-backend-dev"
            # Use same MongoDB Atlas but different database name
            DATABASE_URL="${{ secrets.PROD_DATABASE_URL }}"
            ALLOWED_ORIGINS="${{ secrets.DEV_ALLOWED_ORIGINS || 'http://localhost:5173,http://localhost:4173' }}"
            NODE_ENV="development"
          fi
          
          IMAGE_URI="gcr.io/${{ secrets.GCP_PROJECT_ID }}/timeless-backend:${{ needs.build.outputs.build-id }}-$ENV"
          
          echo "Deploying to Cloud Run service '$SERVICE_NAME'..."
          
          # Deploy with environment variables and security settings
          gcloud run deploy "$SERVICE_NAME" \
            --image "$IMAGE_URI" \
            --platform managed \
            --region ${{ secrets.GCP_REGION || 'australia-southeast1' }} \
            --allow-unauthenticated \
            --set-env-vars "NODE_ENV=$NODE_ENV,PORT=8080" \
            --set-env-vars "DATABASE_URL=$DATABASE_URL" \
            --set-env-vars "JWT_SECRET=${{ secrets.JWT_SECRET }}" \
            --set-env-vars "ALLOWED_ORIGINS=$ALLOWED_ORIGINS" \
            --cpu=1 \
            --memory=512Mi \
            --min-instances=0 \
            --max-instances=10 \
            --timeout=300 \
            --concurrency=80
          
          # Get service URL for output
          SERVICE_URL=$(gcloud run services describe "$SERVICE_NAME" \
            --region=${{ secrets.GCP_REGION || 'australia-southeast1' }} \
            --format='value(status.url)')
          
          echo "Deployment successful!"
          echo "Service URL: $SERVICE_URL"
          echo "Environment: $ENV"
          echo "Build ID: ${{ needs.build.outputs.build-id }}"

      - name: Store deployment revision info for HD requirement
        if: ${{ secrets.GCP_SA_KEY != '' }}
        run: |
          # Skip if no GCP credentials
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "Skipping revision storage - no GCP credentials"
            exit 0
          fi
          
          # Determine service name based on environment
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            SERVICE_NAME="timeless-backend"
            ENV="production"
          else
            SERVICE_NAME="timeless-backend-dev"
            ENV="development"
          fi
          
          # Get revision information for HD requirement
          REVISION_NAME=$(gcloud run revisions list \
            --service="$SERVICE_NAME" \
            --region=${{ secrets.GCP_REGION || 'australia-southeast1' }} \
            --limit=1 \
            --format='value(metadata.name)')
          
          # Create deployment revision manifest - HD requirement
          cat > deployment-revision.json << EOF
          {
            "deployment_id": "${{ needs.build.outputs.build-id }}",
            "git_sha": "${{ github.sha }}",
            "git_ref": "${{ github.ref_name }}",
            "environment": "$ENV",
            "service_name": "$SERVICE_NAME",
            "revision_name": "$REVISION_NAME",
            "deployment_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "workflow_run": "${{ github.run_id }}",
            "image_uri": "gcr.io/${{ secrets.GCP_PROJECT_ID }}/timeless-backend:${{ needs.build.outputs.build-id }}-$(if [[ '${{ github.ref }}' == 'refs/heads/main' ]]; then echo 'prod'; else echo 'dev'; fi)",
            "cloud_run": {
              "region": "${{ secrets.GCP_REGION || 'australia-southeast1' }}",
              "platform": "managed",
              "traffic_allocation": "100%"
            }
          }
          EOF
          
          echo "Deployment revision information stored for HD requirement"
          cat deployment-revision.json

      - name: Upload deployment artifacts for HD requirement
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-deployment-revision-${{ github.sha }}
          path: deployment-revision.json
          if-no-files-found: warn
          retention-days: 90

      - name: Cleanup credentials
        if: always()
        run: rm -f /tmp/gcp-key.json