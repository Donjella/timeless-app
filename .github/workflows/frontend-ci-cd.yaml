name: CI/CD for Timeless Frontend

on:
  push:
    branches: [main, develop]
    paths: ['frontend/**']
  pull_request:
    branches: [main]
    paths: ['frontend/**']
  schedule:
    # Weekly dependency audit
    - cron: '0 3 * * 1'
  workflow_dispatch:
    # Manual trigger with deployment options
    inputs:
      deployment_type:
        description: 'Deployment type'
        required: true
        default: 'preview'
        type: choice
        options:
        - preview
        - staging
        - production
      skip_tests:
        description: 'Skip test suite'
        required: false
        type: boolean
        default: false
      skip_build:
        description: 'Skip build step'
        required: false
        type: boolean
        default: false
      enable_gcs_upload:
        description: 'Upload logs to Google Cloud Storage'
        required: false
        type: boolean
        default: true

# Environment variables for DRY principles
env:
  NODE_VERSION: '20'
  WORKING_DIR: './frontend'

defaults:
  run:
    working-directory: ./frontend

jobs:
  # Job 1: Testing and Quality Assurance
  test:
    runs-on: ubuntu-latest
    
    # Test across multiple Node.js versions for compatibility
    strategy:
      matrix:
        node-version: [18, 20]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run tests
        if: github.event.inputs.skip_tests != 'true'
        run: npm test
        env:
          # Mock backend URL for frontend tests
          VITE_API_URL: http://localhost:5000
          VITE_NODE_ENV: test
          
      - name: Run test coverage
        if: github.event.inputs.skip_tests != 'true'
        run: |
          # Check if coverage dependency exists
          if npm list @vitest/coverage-v8 &>/dev/null; then
            echo "Running coverage with @vitest/coverage-v8..."
            npm run coverage
          else
            echo "Coverage dependency @vitest/coverage-v8 not found"
            echo "Installing coverage dependency..."
            npm install @vitest/coverage-v8 --no-save
            npm run coverage
          fi
        env:
          VITE_API_URL: http://localhost:5000
          VITE_NODE_ENV: test
        continue-on-error: true
        
      - name: Generate test report
        if: always()
        run: |
          echo "# Test Report for Frontend" > test-report.md
          echo "## Environment" >> test-report.md
          echo "- Node.js: ${{ matrix.node-version }}" >> test-report.md
          echo "- Vite: $(npm list vite --depth=0 2>/dev/null | grep vite | cut -d@ -f2 || echo 'Not installed')" >> test-report.md
          echo "- React: $(npm list react --depth=0 2>/dev/null | grep react | cut -d@ -f2 || echo 'Not installed')" >> test-report.md
          echo "- Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> test-report.md
          echo "- Commit: ${{ github.sha }}" >> test-report.md
          echo "- Branch: ${{ github.ref_name }}" >> test-report.md
          echo "- Test Status: $(if [ '${{ github.event.inputs.skip_tests }}' = 'true' ]; then echo 'Skipped'; else echo 'Completed'; fi)" >> test-report.md
          echo "- Coverage: $(if [ -d coverage ]; then echo 'Generated'; else echo 'Not available'; fi)" >> test-report.md
          
      # Store test artifacts in GitHub Actions
      - name: Upload test results to GitHub Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: frontend-test-results-node${{ matrix.node-version }}-${{ github.sha }}
          path: |
            frontend/coverage/
            frontend/test-report.md
          if-no-files-found: warn
          retention-days: 30
          
      # Upload test results to Google Cloud Storage for persistent storage
      - name: Upload test results to Google Cloud Storage
        if: always() && github.event.inputs.enable_gcs_upload != 'false'
        run: |
          # Skip if no GCP credentials (for testing without secrets)
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "GCP credentials not configured, skipping GCS upload"
            echo "This is normal for testing without cloud setup"
            exit 0
          fi
          
          # Setup GCP authentication
          echo "${{ secrets.GCP_SA_KEY }}" | base64 -d > /tmp/gcp-key.json
          export GOOGLE_APPLICATION_CREDENTIALS=/tmp/gcp-key.json
          
          # Install gcloud if not available
          if ! command -v gcloud &> /dev/null; then
            echo "Installing Google Cloud SDK..."
            curl -sSL https://sdk.cloud.google.com | bash
            export PATH="$HOME/google-cloud-sdk/bin:$PATH"
          fi
          
          # Authenticate and configure
          gcloud auth activate-service-account --key-file=/tmp/gcp-key.json
          gcloud config set project ${{ secrets.GCP_PROJECT_ID }}
          
          # Determine environment and bucket
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            BUCKET="${{ secrets.GCS_LOGS_BUCKET_PROD || 'timeless-ci-logs-prod' }}"
            ENV="production"
          else
            BUCKET="${{ secrets.GCS_LOGS_BUCKET_STAGING || 'timeless-ci-logs-staging' }}"
            ENV="staging"
          fi
          
          # Create structured log path for organized storage
          LOG_PATH="frontend/$ENV/${{ github.sha }}/node-${{ matrix.node-version }}/$(date +%Y-%m-%d-%H-%M-%S)"
          
          # Upload test artifacts with parallel processing
          echo "Uploading frontend test results to: gs://$BUCKET/$LOG_PATH"
          
          if [ -d coverage ]; then
            gsutil -m cp -r coverage/ gs://$BUCKET/$LOG_PATH/coverage/
          fi
          
          if [ -f test-report.md ]; then
            gsutil cp test-report.md gs://$BUCKET/$LOG_PATH/test-report.md
            
            # Set metadata for organized storage
            gsutil setmeta \
              -h "x-goog-meta-git-sha:${{ github.sha }}" \
              -h "x-goog-meta-environment:$ENV" \
              -h "x-goog-meta-workflow-run:${{ github.run_id }}" \
              -h "x-goog-meta-node-version:${{ matrix.node-version }}" \
              -h "x-goog-meta-test-status:$(if [ '${{ github.event.inputs.skip_tests }}' = 'true' ]; then echo 'skipped'; else echo 'completed'; fi)" \
              -h "x-goog-meta-component:frontend" \
              gs://$BUCKET/$LOG_PATH/test-report.md
          fi
          
          # Create index file for easy browsing
          cat > log-index.json << EOF
          {
            "workflow_run": "${{ github.run_id }}",
            "git_sha": "${{ github.sha }}",
            "git_ref": "${{ github.ref_name }}",
            "environment": "$ENV",
            "node_version": "${{ matrix.node-version }}",
            "component": "frontend",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "test_status": "$(if [ '${{ github.event.inputs.skip_tests }}' = 'true' ]; then echo 'skipped'; else echo 'completed'; fi)",
            "artifacts": {
              "coverage": "gs://$BUCKET/$LOG_PATH/coverage/",
              "test_report": "gs://$BUCKET/$LOG_PATH/test-report.md",
              "index": "gs://$BUCKET/$LOG_PATH/index.json"
            },
            "github_artifacts": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          }
          EOF
          
          gsutil cp log-index.json gs://$BUCKET/$LOG_PATH/index.json
          
          # Cleanup sensitive files
          rm -f /tmp/gcp-key.json log-index.json
          
          echo "Frontend test results uploaded successfully!"
          echo "View at: https://console.cloud.google.com/storage/browser/$BUCKET/$LOG_PATH"
        continue-on-error: true
          
  # Job 2: Security and Dependency Audit
  security-audit:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run security audit
        run: |
          echo "# Security Audit Report for Frontend" > security-report.md
          echo "## Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> security-report.md
          echo "## Commit: ${{ github.sha }}" >> security-report.md
          echo "" >> security-report.md
          
          echo "## NPM Audit Results" >> security-report.md
          npm audit --audit-level=moderate >> security-report.md 2>&1 || true
          
          echo "" >> security-report.md
          echo "## Package Versions" >> security-report.md
          npm list --depth=0 >> security-report.md 2>&1 || true
          
          echo "" >> security-report.md
          echo "## Outdated Packages" >> security-report.md
          npm outdated >> security-report.md 2>&1 || true
          
          # Also create plain text version for compatibility
          npm audit --audit-level=moderate > security-report.txt 2>&1 || true
          echo "Frontend security audit completed on $(date)" >> security-report.txt
          
      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: frontend-security-audit-${{ github.sha }}
          path: |
            frontend/security-report.md
            frontend/security-report.txt
          if-no-files-found: warn
          retention-days: 90
          
  # Job 3: Build and Package
  build:
    runs-on: ubuntu-latest
    needs: test
    if: github.event.inputs.skip_build != 'true'
    
    outputs:
      build-id: ${{ steps.build-info.outputs.build-id }}
      build-timestamp: ${{ steps.build-info.outputs.timestamp }}
      build-size: ${{ steps.build-analysis.outputs.size }}
      environment: ${{ steps.build-info.outputs.environment }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
          
      - name: Install dependencies
        run: npm ci
        
      - name: Generate build information
        id: build-info
        run: |
          BUILD_ID="$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA::8}"
          TIMESTAMP="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          ENVIRONMENT="${{ github.ref == 'refs/heads/main' && 'production' || 'staging' }}"
          
          echo "build-id=$BUILD_ID" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          
          echo "Build information generated:"
          echo "  Build ID: $BUILD_ID"
          echo "  Environment: $ENVIRONMENT"
          echo "  Timestamp: $TIMESTAMP"
          
      - name: Build project
        run: |
          # Use the same backend URL for both environments
          export VITE_API_URL="${{ secrets.PROD_API_URL || 'https://timeless-backend-461ftmtcsq-ts.a.run.app' }}"
          
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            export VITE_NODE_ENV="production"
          else
            export VITE_NODE_ENV="development"
          fi
          
          echo "Building with configuration:"
          echo "  API URL: $VITE_API_URL"
          echo "  Environment: $VITE_NODE_ENV"
          
          npm run build
          
          echo "Build completed successfully"
          echo "Dist directory contents:"
          ls -la dist/ 2>/dev/null || echo "Dist directory not found"
          
      - name: Analyze build size
        id: build-analysis
        run: |
          if [ -d dist ]; then
            BUILD_SIZE=$(du -sh dist/ | cut -f1)
            echo "size=$BUILD_SIZE" >> $GITHUB_OUTPUT
            
            # Create build analysis report
            echo "# Build Analysis Report" > build-analysis.md
            echo "- Build Size: $BUILD_SIZE" >> build-analysis.md
            echo "- Files Count: $(find dist/ -type f | wc -l)" >> build-analysis.md
            echo "- JS Files: $(find dist/ -name "*.js" | wc -l)" >> build-analysis.md
            echo "- CSS Files: $(find dist/ -name "*.css" | wc -l)" >> build-analysis.md
            echo "- HTML Files: $(find dist/ -name "*.html" | wc -l)" >> build-analysis.md
            echo "- Asset Files: $(find dist/ -name "*.png" -o -name "*.jpg" -o -name "*.svg" -o -name "*.ico" | wc -l)" >> build-analysis.md
            
            # List largest files
            echo "" >> build-analysis.md
            echo "## Largest Files:" >> build-analysis.md
            find dist/ -type f -exec du -h {} + | sort -hr | head -10 >> build-analysis.md
            
            echo "Build size analysis completed: $BUILD_SIZE"
          else
            echo "size=0MB" >> $GITHUB_OUTPUT
            echo "ERROR: dist directory not found after build"
            exit 1
          fi
          
      - name: Create deployment manifest
        run: |
          # Create deployment manifest for workflow data export
          cat > deployment-manifest.json << EOF
          {
            "build_id": "${{ steps.build-info.outputs.build-id }}",
            "git_sha": "${{ github.sha }}",
            "git_ref": "${{ github.ref_name }}",
            "timestamp": "${{ steps.build-info.outputs.timestamp }}",
            "node_version": "${{ env.NODE_VERSION }}",
            "environment": "${{ steps.build-info.outputs.environment }}",
            "build_size": "${{ steps.build-analysis.outputs.size }}",
            "api_endpoint": "${{ secrets.PROD_API_URL || 'https://timeless-backend-461ftmtcsq-ts.a.run.app' }}",
            "deployment_type": "${{ github.event.inputs.deployment_type || 'auto' }}",
            "assets": {
              "dist_folder": "./dist",
              "entry_point": "index.html",
              "build_tool": "vite"
            },
            "vite_config": {
              "base_url": "/",
              "output_dir": "dist"
            }
          }
          EOF
          
          echo "Deployment manifest created:"
          cat deployment-manifest.json
          
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build-${{ github.sha }}
          path: |
            frontend/dist/
            frontend/deployment-manifest.json
          if-no-files-found: error
          retention-days: 30
          
      - name: Upload build analysis
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build-analysis-${{ github.sha }}
          path: frontend/build-analysis.md
          if-no-files-found: warn
          retention-days: 30

  # Job 4: Deploy to Google Cloud Storage
  deploy:
    runs-on: ubuntu-latest
    needs: [test, build]
    if: |
      github.ref == 'refs/heads/main' ||
      github.ref == 'refs/heads/develop' ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.deployment_type == 'production')
    
    # Override global working directory for deployment job
    defaults:
      run:
        working-directory: .
    
    outputs:
      website-url: ${{ steps.deploy-info.outputs.website-url }}
      bucket-name: ${{ steps.deploy-info.outputs.bucket-name }}
    
    steps:
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: frontend-build-${{ github.sha }}
          path: ./frontend-build/
          
      - name: Validate deployment package
        run: |
          echo "Validating deployment package..."
          echo "Build artifacts structure:"
          find ./frontend-build -type f | head -20
          
          # Check if critical files exist
          if [[ ! -f "./frontend-build/dist/index.html" ]]; then
            echo "ERROR: index.html not found in build"
            exit 1
          fi
          
          if [[ ! -f "./frontend-build/deployment-manifest.json" ]]; then
            echo "ERROR: deployment-manifest.json not found"
            exit 1
          fi
          
          echo "Deployment package validation successful"
          
      - name: Authenticate to Google Cloud
        run: |
          # Skip if no GCP credentials
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "GCP credentials not configured, skipping deployment"
            echo "This is normal for testing without cloud setup"
            exit 0
          fi
          
          # Setup GCP authentication
          echo "${{ secrets.GCP_SA_KEY }}" | base64 -d > /tmp/gcp-key.json
          
          # Install gcloud if not available
          if ! command -v gcloud &> /dev/null; then
            echo "Installing Google Cloud SDK..."
            curl -sSL https://sdk.cloud.google.com | bash
            export PATH="$HOME/google-cloud-sdk/bin:$PATH"
          fi
          
          # Authenticate and configure
          gcloud auth activate-service-account --key-file=/tmp/gcp-key.json
          gcloud config set project ${{ secrets.GCP_PROJECT_ID }}
          
          echo "Google Cloud authentication successful"

      - name: Create and Configure Storage Bucket
        run: |
          # Skip if no GCP credentials
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "Skipping bucket creation - no GCP credentials"
            exit 0
          fi
          
          # Determine environment-specific bucket name
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            BUCKET_NAME="timeless-frontend-prod"
            ENV="production"
          else
            BUCKET_NAME="timeless-frontend-dev"
            ENV="development"
          fi
          
          echo "Creating and configuring bucket: $BUCKET_NAME"
          
          # Create bucket if it doesn't exist
          if ! gsutil ls gs://$BUCKET_NAME >/dev/null 2>&1; then
            echo "Creating new bucket: gs://$BUCKET_NAME"
            gsutil mb -l ${{ secrets.GCP_REGION || 'australia-southeast1' }} gs://$BUCKET_NAME
          else
            echo "Bucket already exists: gs://$BUCKET_NAME"
          fi
          
          # Configure bucket for website hosting
          gsutil web set -m index.html -e 404.html gs://$BUCKET_NAME
          
          # Make bucket publicly readable
          gsutil iam ch allUsers:objectViewer gs://$BUCKET_NAME
          
          # Set CORS policy for frontend assets
          cat > cors.json << EOF
          [
            {
              "origin": ["*"],
              "method": ["GET", "HEAD"],
              "responseHeader": ["Content-Type"],
              "maxAgeSeconds": 3600
            }
          ]
          EOF
          gsutil cors set cors.json gs://$BUCKET_NAME
          
          echo "Bucket configured successfully for website hosting"

      - name: Deploy to Cloud Storage
        id: deploy-info
        run: |
          # Skip if no GCP credentials
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "Skipping deployment - no GCP credentials"
            exit 0
          fi
          
          # Determine environment-specific settings
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            BUCKET_NAME="timeless-frontend-prod"
            ENV="production"
          else
            BUCKET_NAME="timeless-frontend-dev"
            ENV="development"
          fi
          
          echo "Deploying frontend to: gs://$BUCKET_NAME"
          
          # Clear existing files to ensure clean deployment
          echo "Clearing existing files from bucket..."
          gsutil -m rm gs://$BUCKET_NAME/** || echo "No existing files to remove"
          
          # Upload all files from dist directory
          echo "Uploading frontend files..."
          gsutil -m cp -r ./frontend-build/dist/* gs://$BUCKET_NAME/
          
          # Set cache control headers for performance
          echo "Setting cache control headers..."
          gsutil -m setmeta -h "Cache-Control:public, max-age=31536000" gs://$BUCKET_NAME/assets/**
          gsutil -m setmeta -h "Cache-Control:public, max-age=3600" gs://$BUCKET_NAME/*.html
          gsutil -m setmeta -h "Cache-Control:public, max-age=86400" gs://$BUCKET_NAME/*.js
          gsutil -m setmeta -h "Cache-Control:public, max-age=86400" gs://$BUCKET_NAME/*.css
          
          # Generate website URL
          WEBSITE_URL="https://storage.googleapis.com/$BUCKET_NAME/index.html"
          
          echo "bucket-name=$BUCKET_NAME" >> $GITHUB_OUTPUT
          echo "website-url=$WEBSITE_URL" >> $GITHUB_OUTPUT
          
          echo "Deployment successful!"
          echo "Bucket: gs://$BUCKET_NAME"
          echo "Website URL: $WEBSITE_URL"
          echo "Environment: $ENV"
          echo "Build ID: ${{ needs.build.outputs.build-id }}"

      - name: Store deployment information
        run: |
          # Skip if no GCP credentials
          if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
            echo "Skipping deployment info storage - no GCP credentials"
            exit 0
          fi
          
          # Determine environment
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            ENV="production"
            BUCKET_NAME="timeless-frontend-prod"
          else
            ENV="development"
            BUCKET_NAME="timeless-frontend-dev"
          fi
          
          # Create deployment info manifest
          cat > frontend-deployment.json << EOF
          {
            "deployment_id": "${{ needs.build.outputs.build-id }}",
            "git_sha": "${{ github.sha }}",
            "git_ref": "${{ github.ref_name }}",
            "environment": "$ENV",
            "bucket_name": "$BUCKET_NAME",
            "website_url": "${{ steps.deploy-info.outputs.website-url }}",
            "deployment_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "workflow_run": "${{ github.run_id }}",
            "build_size": "${{ needs.build.outputs.build-size }}",
            "cloud_storage": {
              "region": "${{ secrets.GCP_REGION || 'australia-southeast1' }}",
              "public_access": true,
              "cors_enabled": true,
              "cache_control": "optimized"
            },
            "assets": {
              "total_files": "$(find ./frontend-build/dist -type f | wc -l)",
              "entry_point": "index.html",
              "build_tool": "vite"
            }
          }
          EOF
          
          echo "Frontend deployment information stored"
          cat frontend-deployment.json

      - name: Upload deployment artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: frontend-deployment-info-${{ github.sha }}
          path: frontend-deployment.json
          if-no-files-found: warn
          retention-days: 90

      - name: Cleanup credentials
        if: always()
        run: rm -f /tmp/gcp-key.json cors.json